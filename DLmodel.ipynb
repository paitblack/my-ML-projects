{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, Dense, Dropout, Dense, LSTM\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advertisement</td>\n",
       "      <td>poster quot literari quot art print minimalist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advertisement</td>\n",
       "      <td>gtse 100 brown plastic masonri wall plug 70mm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advertisement</td>\n",
       "      <td>barn swallow graphit print basebal cap men wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advertisement</td>\n",
       "      <td>women fromi flipflop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advertisement</td>\n",
       "      <td>320 pc heat shrink spade connector femal male ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                              title\n",
       "0  Advertisement  poster quot literari quot art print minimalist...\n",
       "1  Advertisement  gtse 100 brown plastic masonri wall plug 70mm ...\n",
       "2  Advertisement  barn swallow graphit print basebal cap men wom...\n",
       "3  Advertisement                               women fromi flipflop\n",
       "4  Advertisement  320 pc heat shrink spade connector femal male ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"last.csv\",encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#things that have implemented to the dataset : lower(), remove punct, stopword removal...\n",
    "# stopword removal have not imp. to class named Friends & Family.\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"title\"].astype(str).tolist()\n",
    "y = df[\"category\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Advertisement' 'News' 'Work']\n"
     ]
    }
   ],
   "source": [
    "lencoder = LabelEncoder()\n",
    "y = lencoder.fit_transform(y)\n",
    "\n",
    "print(lencoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertisement -> 0\n",
      "News -> 1\n",
      "Work -> 2\n"
     ]
    }
   ],
   "source": [
    "for i, category in enumerate(lencoder.classes_):\n",
    "    print(f\"{category} -> {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_padd = pad_sequences(X_seq, maxlen=45, padding=\"post\",truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_padd, y, test_size=0.2, random_state=10,shuffle=True)\n",
    "X_train = X_train[~np.isnan(X_train).any(axis=1)]\n",
    "X_test = X_test[~np.isnan(X_test).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Train Count  Test Count\n",
      "Category                         \n",
      "0               39922        9812\n",
      "2               39691       10043\n",
      "1               39748        9986\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "train_counts = Counter(y_train)\n",
    "test_counts = Counter(y_test)\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(train_counts, orient='index', columns=['Train Count'])\n",
    "test_df = pd.DataFrame.from_dict(test_counts, orient='index', columns=['Test Count'])\n",
    "\n",
    "category_distribution = pd.concat([train_df, test_df], axis=1).fillna(0)\n",
    "category_distribution.index.name = \"Category\"\n",
    "\n",
    "print(category_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=45),\n",
    "    Bidirectional(LSTM(128,  return_sequences=True, kernel_regularizer=regularizers.l2(0.001))),\n",
    "    Dropout(0.5),\n",
    "    Bidirectional(LSTM(64,kernel_regularizer=regularizers.l2(0.001))),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(set(y)),activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"SparseCategoricalCrossentropy\", optimizer=Adam(1e-5), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 31ms/step - accuracy: 0.5196 - loss: 1.6121 - val_accuracy: 0.7667 - val_loss: 0.9938\n",
      "Epoch 2/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 32ms/step - accuracy: 0.7929 - loss: 0.8986 - val_accuracy: 0.9048 - val_loss: 0.5291\n",
      "Epoch 3/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 31ms/step - accuracy: 0.8985 - loss: 0.5623 - val_accuracy: 0.9264 - val_loss: 0.4264\n",
      "Epoch 4/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 32ms/step - accuracy: 0.9220 - loss: 0.4597 - val_accuracy: 0.9383 - val_loss: 0.3652\n",
      "Epoch 5/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 32ms/step - accuracy: 0.9363 - loss: 0.3945 - val_accuracy: 0.9476 - val_loss: 0.3270\n",
      "Epoch 6/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 32ms/step - accuracy: 0.9463 - loss: 0.3470 - val_accuracy: 0.9539 - val_loss: 0.2935\n",
      "Epoch 7/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 32ms/step - accuracy: 0.9520 - loss: 0.3137 - val_accuracy: 0.9573 - val_loss: 0.2729\n",
      "Epoch 8/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 32ms/step - accuracy: 0.9564 - loss: 0.2933 - val_accuracy: 0.9581 - val_loss: 0.2604\n",
      "Epoch 9/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 34ms/step - accuracy: 0.9608 - loss: 0.2680 - val_accuracy: 0.9613 - val_loss: 0.2438\n",
      "Epoch 10/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 32ms/step - accuracy: 0.9623 - loss: 0.2554 - val_accuracy: 0.9620 - val_loss: 0.2370\n",
      "Epoch 11/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 32ms/step - accuracy: 0.9660 - loss: 0.2389 - val_accuracy: 0.9632 - val_loss: 0.2250\n",
      "Epoch 12/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 32ms/step - accuracy: 0.9671 - loss: 0.2237 - val_accuracy: 0.9624 - val_loss: 0.2233\n",
      "Epoch 13/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 33ms/step - accuracy: 0.9691 - loss: 0.2125 - val_accuracy: 0.9637 - val_loss: 0.2155\n",
      "Epoch 14/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 35ms/step - accuracy: 0.9705 - loss: 0.2014 - val_accuracy: 0.9615 - val_loss: 0.2150\n",
      "Epoch 15/15\n",
      "\u001b[1m3731/3731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 34ms/step - accuracy: 0.9705 - loss: 0.1955 - val_accuracy: 0.9663 - val_loss: 0.1987\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=15,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=32,\n",
    "                    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.saving\n",
    "\n",
    "keras.saving.save_model(model, 'doksanyedi-ondokuz.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model1 = load_model(\"doksanyedi-ondokuz.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Tahmin edilen kategori: 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Tahmin edilen kategori: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Tahmin edilen kategori: 2\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.lower().translate(translator).split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "def process_input_text(text):\n",
    "    text = remove_stopwords(text)\n",
    "    text_sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(text_sequence, maxlen=45, padding=\"post\",truncating=\"post\")\n",
    "    return padded_sequence\n",
    "\n",
    "input_texts = [\"Google's artificial intelligence course is available with a %50 discount.\",\"The oldest living fish species has been discovered\",\"send me the Java files - lead\"]\n",
    "\n",
    "for input_text in input_texts:\n",
    "    processed_input = process_input_text(input_text)\n",
    "\n",
    "    prediction = model.predict(processed_input)\n",
    "\n",
    "    predicted_category = prediction.argmax()\n",
    "    print(f\"Tahmin edilen kategori: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
